{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classification_dataset = load_dataset(\"rotten_tomatoes\")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"microsoft/deberta_v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers import DataCollatorsWithPadding\n",
    "data_collator = DataCollatorsWithPadding(tokenizer = tokenizer) #for batches of data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_classification = text_classification_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(1)\n",
    "tokenizer.convert_ids_to_tokens(2)\n",
    "tokenized_classification[\"train\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model= AutoModelForSequence.from_pretrained(model_name, num_labels=np.unique(text_classification_dataset[\"train\"][\"labels\"].shape[0]))\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"my_deberta_review_model\",\n",
    "                                   learning_rate = 2e-5\n",
    "                                   per_device_train_batch_size = 16,\n",
    "                                   per_device_eval_batch_size =16,\n",
    "                                   num_train_epochs =1,\n",
    "                                   weight_decay =0.01,\n",
    "                                   evaluation_strategy = \"epoch\",\n",
    "                                   save_strategy = \"epoch\",\n",
    "                                   load_best_model_at_end = True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_classification[\"train\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "text = \"the movie was no terrible. i really hate it\"\n",
    "inputs = tokenizer(text, return_tensors = \"pt\").to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "    logit.shape\n",
    "    logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def init_normal(m):\n",
    "    if type(m)== Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        # use the modules apply function to recursively apply the initialization\n",
    "        model.apply(init_normal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKEN CLASSIFICATION TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token_classification_dataset = load_dataset(\"conll2003\")\n",
    "token_classification_dataset[\"train\"]\n",
    "target_col = \"ner_tags\" # or \"pos_tag\"\n",
    "label_list = token_classification_dataset[\"train\"].features[target_col].feature.names\n",
    "tokenized_input = tokenizer(token_classification_dataset[\"train\"][\"tokens\"], is_split_into_words = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels (examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation = True, is_split_into_words= True)\n",
    "    labels = []\n",
    "    for i, label in enumerate (examples [target_col]):\n",
    "        word_ids = tokenized_inputd.word_ids(batch_index=i)\n",
    "        #map tokens to their respective word\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            #set the special tokens to -100\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx !=previous_word_idx:\n",
    "                #only label the first token of a given word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"]= labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = token_classification_dataset.map(tokenize_and_align_labels, batched = True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Seqeval\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = label_list\n",
    "def compute_metrics(p):\n",
    "    predictions, labels =p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    true_predictions = [(label_list[p] for (p,1) in zip(prediction, label) if 1 !=-100] for prediction, label in zip(predictions, labels))]\n",
    "    return {\"precison\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {num:label for num, label in enumerate(label_list)}\n",
    "label1id = {label: num, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForTokenClassification.from_pretrained( model_name,\n",
    "                                                        num_labels = len(label_list),\n",
    "                                                        id2label = id2label,\n",
    "                                                        label2id = label2id,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"my_deberta_review_model\",\n",
    "                                   learning_rate = 2e-5\n",
    "                                   per_device_train_batch_size = 16,\n",
    "                                   per_device_eval_batch_size =16,\n",
    "                                   num_train_epochs =1,\n",
    "                                   weight_decay =0.01,\n",
    "                                   evaluation_strategy = \"epoch\",\n",
    "                                   save_strategy = \"epoch\",\n",
    "                                   load_best_model_at_end = True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_classification[\"train\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "text \"some input I want my model to part of speech tag\"\n",
    "inputs = tokenizer (text, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**input).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    predicted_token_class = [model.config.id2label[t.items()] for t in predictions[0]]\n",
    "    for text, pred_class in zip(inputs.tokens(), predicted_token_class):\n",
    "        print(text, pred_class)\n",
    "        logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
